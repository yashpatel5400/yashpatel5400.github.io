\title{Conformal Contextual Robust Optimization}

\author{ Eduardo Ochoa Rivera\* \And Yash Patel\* \And  Ambuj Tewari }

\begin{abstract}
  Distribution-free uncertainty estimation for ensemble methods is increasingly desirable due to the widening deployment of multi-modal black-box predictive models. Conformal prediction is one approach that avoids making strong distributional assumptions. Methods for conformal aggregation have been proposed for ensembled prediction, where the prediction regions of individual models are merged to retain coverage guarantees while minimizing conservatism. Merging the prediction \textit{regions} directly, however, can miss out on opportunities to further reduce conservatism by exploiting structures present in the conformal \textit{scores}. We, therefore, propose a novel framework that extends the standard scalar formulation of a score function to a multivariate score that produces more efficient prediction regions. We then demonstrate that such a framework can be efficiently leveraged in both classification and predict-then-optimize regression settings downstream and empirically show the advantage over alternate conformal aggregation methods.
\end{abstract}

\section{Introduction}\label{section:intro}
Ensemble methods are an oft-used class of statistical modeling techniques due to their ability to reduce variance or improve predictive accuracy \cite{schapire1999brief,zhang2012ensemble,dietterich2000ensemble}. 
Such methods are increasingly being coupled with complex, black-box models, such as in multi-modal language models  \cite{zhang2023adding,radford2021learning,sun2013survey,zhao2017multi,yan2021deep}. Couplings of this sort are seeing ever-widening deployment in safety-critical settings, such as medicine \cite{yuan2018multi,li2018review,yuan2017multi} and robotics \cite{brena2020choosing,blasch2021machine,alatise2020review}.  

Increasing interest is, therefore, now being placed on quantifying uncertainty for such models \cite{subedar2019uncertainty,tian2020uno,denker1990transforming,havasi2020training,malinin2018predictive}. Towards this end, methods of uncertainty quantification have arisen, such as deep ensembles and committee estimation \cite{rahaman2021uncertainty,abdar2021review,carrete2023deep}. Such methods, however, sacrifice generality with the imposition of distributional assumptions, motivating the need for distribution-free uncertainty quantification for ensemble methods. 

One method for performing distribution-free uncertainty quantification is conformal prediction, which provides a principled framework for producing distribution-free prediction regions with marginal frequentist coverage guarantees \cite{angelopoulos2021gentle, shafer2008tutorial}. By using conformal prediction on a user-defined score function, prediction regions attain marginal coverage guarantees.
While calibration is guaranteed from this procedure, predictive efficiency, i.e., the size of the resulting prediction regions, can be large for poorly chosen score functions.

As a result, methods have arisen to perform conformal model aggregation, which both provide uncertainty estimates of the ensembled predictions and do so in ways as to minimize the prediction region size \cite{gasparin2024conformal,trunov2023online,yang2024selection,v2023online,gasparin2024merging}. While such approaches succeed in reducing the prediction region size over naive aggregation, they all aggregate the \textit{separately conformalized} prediction regions of the predictors in the ensemble. In doing so, they forgo the possibility of automatically leveraging shared structure amongst the scores of the individual predictors, resulting in conservative prediction regions.

\begin{figure*}
  \centering 
  \includegraphics[width=1.0\textwidth]{workflow.png}
  \caption{CSA provides a principled extension to the standard conformal prediction pipeline by leveraging ideas from higher-dimensional quantile regression to define quantile envelopes $\widehat{\mathcal{Q}}$ instead of scalar quantiles $\widehat{q}$. It does so by evaluating a collection of score functions (here $s_1$ and $s_2$) over the calibration dataset to define $\mathcal{S}$, finding quantiles $\{\widehat{q}_{m}\}$ over a set of projection directions $\{u_{m}\}$, and taking $\widehat{\mathcal{Q}}$ to be the intersection of the resulting half-planes $H(u_{m},\widehat{q}_{m})$. 
  These quantile envelopes result in more informative prediction regions that can be used in downstream tasks. 
  }
\end{figure*}

We instead propose to perform aggregation in \textit{score space} by extending traditional conformal prediction to consider a multivariate score function and defining prediction regions using ``quantile envelopes'' in place of scalar quantiles. Doing so enables efficient, data-driven, automated conformal model aggregation. We demonstrate that this formulation retains the desired distribution-free coverage guarantees typical of standard conformal prediction and that the resulting prediction regions can be used efficiently in both classification and regression settings. Our contributions are: 

\begin{itemize}
    \item Providing a multivariate extension to conformal prediction, dubbed ``conformal score aggregation'' (CSA), that leverages quantile envelopes to enable data-driven, informative uncertainty estimation for model ensembles while retaining coverage guarantees.
    \item Demonstrating how the prediction regions resulting from CSA can be efficiently leveraged in downstream predict-then-optimize regression tasks.
    \item Demonstrating the empirical improvement of the CSA framework over alternate conformal aggregation strategies across classification and regression settings.
\end{itemize}

\section{Background}\label{section:background}
\subsection{Conformal Prediction}
Coverage guarantees of uncertainty quantification methods generally rely on distributional assumptions, often via asymptotics or explicit specification. To alleviate the need for such restrictive assumptions, interest in finite-sample, distribution-free uncertainty quantification methods has risen. Conformal prediction is one such method \cite{angelopoulos2021gentle, shafer2008tutorial}. 

Conformal prediction serves as a wrapper around such predictors, producing prediction regions $\mathcal{C}(x)$ that have formal guarantees of the form $\mathcal{P}_{X,Y}(Y \notin \mathcal{C}(X))\leq \alpha$ for some prespecified level $\alpha$. To achieve this, ``split conformal'' partitions the dataset  $\mathcal{D} = \{(x_i,y_i)\}_{i=1}^{N}$ into a training set $\mathcal{D}_T$ and a calibration set $\mathcal{D}_C$. The former serves as the data used to fit $\widehat{f}$. 
Users of conformal prediction must then design a ``score function'' $s(x,y)$, which should quantify ``test error'', often in a domain-specific manner. For instance, a simple score function for a regression setting would be $s(x,y)=\Vert\hat f(x)-y\Vert$. This score function is then evaluated across the calibration set to define $\mathcal{S}_{C} = \{s(x, y)\mid (x, y)\in\mathcal{D}_C\}$. For a desired coverage of $1-\alpha$, we then take $\widehat{q}$ to be the $\ceil{(|\mathcal{D}_{C}|+1)(1-\alpha)}/|\mathcal{D}_{C}|$ quantile of $\mathcal{S}_{C}$, with which prediction regions for future test queries $x$ can be defined as $\mathcal{C}(x) = \{y \mid s(x, y) \le \widehat{q}\}$. Under the exchangeability of the score of a test point $s(X', Y')$ with $\mathcal{S}_{C}$, we have the desired \textit{finite-sample} probabilistic guarantee that $1 - \alpha\le\mathcal{P}_{X',Y'}(Y' \in \mathcal{C}(X'))$.

While this guarantee holds for any $s(x,y)$, the informativeness of the resulting prediction regions, quantified as the inverse expected Lebesgue measure across $X$, i.e. $\left(\mathbb{E}[\mathcal{L}(\mathcal{C}(X))]\right)^{-1}$, is intimately tied to its specification \cite{shafer2008tutorial}. Thus, much of the challenge of conformal prediction relates to choosing a score function that retains coverage while minimizing region size. 

\subsection{Quantile Envelopes}\label{section:quantile_envelopes}
Generalizations of quantiles have a long history in statistics \cite{rousseeuw1998computing,serfling2002quantile}. 
Unlike univariate data, multivariate data do not lend itself to an unambiguous definition of a quantile, as there is no canonical ordering in higher dimensional spaces. 
The notion of a ``directional quantile'' for a random variable $X \in\mathbb{R}^{n}$ can, however, be directly defined given some direction $u\in\mathcal{S}^{n-1}$, namely as $Q(X, \alpha, u) = \inf \{q \in \mathbb{R}: \mathcal{P}(u^{\top}X \leq q) \geq \alpha\}$ \cite{kong2012quantile,paindaveine2011directional,hallin2010multivariate}. When there is no ambiguity, we just denote it as $Q(\alpha, u)$. 
For any given $u$, notice the choice of quantile defines a corresponding halfplane $H(u, Q(\alpha, u)) =\left\{x \in \mathcal{X}: u^{\top} x \leq Q(\alpha, u)\right\}$. 
The quantile envelope is then the intersection thereof:
\begin{equation}\label{eqn:quantile_envelope}
    D(\alpha) = \bigcap_{u\in\mathcal{S}^{n-1}} H(u, Q(\alpha, u)).
\end{equation} 
Notably, while each individual $H(u, Q(\alpha, u))$ captures $1-\alpha$ of the points, $D(\alpha)$ does \textit{not}, as it is the intersection thereof and hence captures $<1-\alpha$ of the mass. If $1-\alpha$ combined coverage is sought, a correction, such as Bonferroni adjustment, is used for the individual planes.

\subsection{Related Works}\label{section:related_works}
Ensemble methods consist of $K$ predictors $f_{k}:\mathcal{X}_{k}\rightarrow\mathcal{Y}$;
notably, such predictors need not map from the same set of covariates. A naive approach for uncertainty quantification would then be to conformalize the ensembled predictor. That is, for an ensembling algorithm $\mathcal{F} : \mathcal{Y}^{K}\rightarrow\mathcal{Y}$, a score function
    $s(\mathcal{F}(f_{1}(x),...,f_{K}(x)), y)$
would be defined. 
Denoting the $\ceil{(N_{\mathcal{C}}+1)(1-\alpha)}/N_{\mathcal{C}}$ quantile of the score distribution over $\mathcal{D}_{C}$ as $\widehat{q}(\alpha)$, $\mathcal{C}(x)=\{y : s(x, y) \leq \widehat{q}(\alpha)\}$ would then be calibrated. 

Such an approach, however, lacks some desirable properties. In particular, prediction regions $\mathcal{C}(x)$ should have the quality that, if a particular predictor has less uncertainty in its predictions, as is frequently true of ensemble settings where the predictors span multiple input data modalities, upon routing to that predictor, the corresponding size of the prediction region should be smaller than if it had been routed to a different predictor. While the naive approach does, in principle, support this property, it ultimately relies on defining an \textit{uncertainty-aware} ensembling algorithm $\mathcal{F}$. In its typical form, however, $\mathcal{F}$ simply takes \textit{point predictions} $f_{1}(x),...,f_{K}(x)$ in as input, meaning any uncertainty-awareness would need to be baked in a priori into the definition of $\mathcal{F}$ through domain knowledge of the uncertainties of the predictors $f_{1},...,f_{K}$, which can seldom be specified precisely, sacrificing the predictive efficiency of $\mathcal{C}(x)$.

Conformal model aggregation, thus, seeks to mitigate these deficiencies by aggregating the prediction regions $\mathcal{C}_{1}(x),...,\mathcal{C}_{K}(x)$ rather than the individual point predictions \cite{gasparin2024conformal,yang2024selection,v2023online,gasparin2024merging}. While there are several methods in this vein, they can be categorized into one of two general approaches. 
The first line of work seeks to perform model \textit{selection}, in which a single conformal predictor is selected $\mathcal{C}_{k^{*}}$, typically based on the criterion of minimizing region size $k^{*} := \argmin_{k} \mathbb{E}[\mathcal{L}(\mathcal{C}_{k}(X))]$ \cite{yang2024selection,v2023online}.

Generally, however, methods leveraging the full collection of predictors produce less conservative regions \cite{gasparin2024conformal,gasparin2024merging}. Such works aggregate the individual prediction regions into a final region by defining $\mathcal{C}(x) := \{ y\mid \sum_{k=1}^{K} w_{k} \mathbb{I}[y\in\mathcal{C}_k(x)] \ge\widehat{a} \}$ for weights $\{w_{k}\}\in[0,1]$ such that $\sum_{k=1}^{K} w_{k} = 1$ and a threshold $\widehat{a}$. Methods then differ in the procedure by which $\{w_{k}\}$ and $\widehat{a}$ are prescribed, several of which were prescribed by \cite{gasparin2024merging}. We note that the methods of \cite{gasparin2024conformal} are designed for a different setting than that considered herein, namely that in which conformal coverage is sought adaptively over data streams.

In this vein, \cite{luo2024weighted} have recently proposed a vector-score extension as that discussed herein, in which candidate weight vectors $\{w_{m}\}\in\mathbb{R}^{K}$ are searched over for score aggregation. That is, a vector $s(x) := (s_{1}(x,y),...,s_{K}(x,y))\in\mathbb{R}^{K}$ of scores $s_{k}(x,y)$ corresponding to each predictor $f_{k}(x)$ is predicted and its aggregate prediction region defined on the projection $\langle w_{m^*}, s\rangle$ for $w_{m^*}$ the weight resulting in the smallest prediction region. This method, however, has two shortcomings addressed herein. The first is that their method can only be applied in classification settings, whereas our method can be leveraged across both regression and classification problems. The second is that their approach only uses a \textit{single} weighted projection in the end, resulting in suboptimal aggregation and, therefore, conservative prediction regions.

\section{Method}\label{section:method}

\subsection{Multivariate Score Quantile}\label{section:csa_envelope}

We consider the setting typical of conformal model aggregation, as discussed in \Cref{section:related_works}, in which predictors $f_{1}(x),...,f_{K}(x)$ and corresponding scores $s_{1}(x,y),...,s_{K}(x,y)$ are defined. We assume a similar premise as \cite{luo2024weighted}, in which
the scores are stacked into a multivariate score $s(x,y) := (s_{1}(x,y),...,s_{K}(x,y))$. A naive approach would then leverage standard conformal prediction over a pre-defined map $g : \mathbb{R}^{K}\rightarrow\mathbb{R}$, e.g., $g(s) = \sum_{k=1}^{K} s_k$. 
Similar to the naive conformalization of an ensembled predictor discussed in \Cref{section:related_works}, using a \textit{fixed} $g$ fails to adapt to any disparities in uncertainties present across predictors or requires intimate knowledge of such uncertainties.
We instead wish to provide a data-adaptive pipeline to automatically produce such a $g$. 

Importantly, we hereafter assume the score functions are non-negative, i.e., $s_{k} : \mathcal{X}\times\mathcal{Y}\rightarrow\mathbb{R}_{+}$, which is typically the case as the score serves as a generalization of the residual. We highlight that many of the details of the method presented below are geometric in nature and are more easily understood with the supplement of diagrams. 

\subsubsection{Score Partial Ordering}\label{section:csa_ordering}
Intuitively, our method seeks to directly generalize the approach of split conformal, by ``ordering'' the collection of multivariate calibration scores and taking the $1-\alpha$ score under such an ordering to be a threshold $\widehat{\mathcal{Q}}$ with which prediction regions are then implicitly defined. 
Formally, the multivariate ``ordering'' is established as a 
pre-ordering $\lesssim$ over $\mathbb{R}^{K}$; a pre-ordering differs from a total ordering in that it need not satisfy the antisymmetric axiom of a total ordering. Roughly speaking, an ``acceptance region,'' so called as it serves as the criterion used to ultimately decide which $y$ are accepted into the prediction region, is then defined as $\widehat{\mathcal{Q}} := \{s\mid s\lesssim\widehat{q}\}$, where $\widehat{q}$ is the $1-\alpha$ empirical quantile of $\mathcal{S}_C$ under $\lesssim$. Such a $\widehat{\mathcal{Q}}$ naturally generalizes the standard scalar acceptance interval of $[0,\widehat{q}]$ in the case of non-negative score functions. We briefly highlight the distinction between \textit{acceptance regions} and \textit{prediction regions}. The former are subsets of the space $\subset\mathbb{R}^{K}$ of multivariate scores that ultimately define the criteria for retaining particular $y$ values in the prediction region. The latter are the subsets of the output space $\mathcal{Y}$ and it is these that ultimately have coverage guarantees. The two, however, are directly related; in particular, for a fixed score $s(x,y)$, a larger acceptance region will result in a more conservative prediction region.

Crucially, therefore, the problem of choosing this pre-ordering closely parallels that of choosing $g$, where a poorly chosen pre-ordering will result in overly large acceptance regions and, hence, conservative prediction regions. For instance, using a lexicographical ordering $\lesssim_{\mathrm{Lex}}$ will result in axis-aligned hyper-rectangular acceptance regions.
As a result, rather than manually prescribing a pre-ordering, we define $\lesssim$ in a data-driven fashion by prescribing an indexed family of nested sets $\{\mathcal{A}_{t}\}_{t\in\mathbb{R}}$, such that $\mathcal{A}_{t_{1}}\subset\mathcal{A}_{t_{2}}$ for $t_{1}\le t_{2}$ and stating $s_1 \lesssim s_2$ if $\forall t$, $s_2\in\mathcal{A}_{t}\implies s_1\in\mathcal{A}_{t}$. 

For a family of sets $\{\mathcal{A}_{t}\}_{t\in\mathbb{R}}$, we take each $\mathcal{A}_{t}$ to be the region of the positive orthant $\mathbb{R}_{+}^{K}$ bounded by the coordinate axes and an ``outer frontier'' parameterized by $t$. 
The shape of this outer frontier remains fixed over the family and is merely scaled outward from the origin with $t$. Under this choice, comparing $s_1,s_2\in\mathbb{R}^{K}$, i.e., checking if $s_1\lesssim s_2$, amounts to checking if $t(s_1)\le t(s_2)$, where $t(s)$ is the smallest $t$ for which the outer frontier of $\mathcal{A}_{t}$ intersects $s$. Notably, $t(s)$ is precisely the aforementioned data-driven score fusion function $g(s)$ of interest. Defining a data-adaptive $g(s)$, therefore, reduces to having a data-driven approach for defining the outer frontier of $\mathcal{A}_{t}$. We restrict this outer frontier to be such that $\mathcal{A}_{t}$ is a convex set; if $\mathcal{A}_{t}$ were permitted to be nonconvex, computing $t(s) := \min \{t\in\mathbb{R}: s\in\mathcal{A}_{t}\}$ would potentially be computationally expensive.

To have tight acceptance regions, we formally wish for the pre-ordering to have the property that the acceptance region given by $\widetilde{\mathcal{Q}}$ has minimal Lebesgue measure and captures $1-\alpha$ points of $\mathcal{S}_C$. The problem of discovering an optimal pre-ordering can, thus, be equivalently stated as seeking to define the outer frontier of $\mathcal{A}_t$ to match that of the tightest $1-\alpha$ convex cover of $\mathcal{S}_C$. 

This motivates selecting the outer frontier to be the $1-\alpha$ quantile envelope of $\mathcal{S}_C$. Using $\mathcal{S}_C$ to define $\mathcal{A}_t$ and in turn $\lesssim$, however, sacrifices the exchangeability of its points with test scores $s'$, as the very nature of ordering would change in swapping $s'$ with any $s\in\mathcal{S}_C$. The goal follows as seeking to define the outer frontier as the $1-\alpha$ quantile envelope of $\mathcal{S}_C$ without directly using $\mathcal{S}_C$. For this reason, we partition $\mathcal{S}_C = \mathcal{S}_C^{(1)}\cup \mathcal{S}_C^{(2)}$, where we define $\lesssim$ using $\mathcal{S}_C^{(1)}$ and compute $\widehat{q}$ over $\mathcal{S}_C^{(2)}$. Such a split is predicated on the assumption that the $1-\alpha$ quantile envelope defined over $\mathcal{S}_C^{(1)}$ resembles that of $\mathcal{S}_C^{(2)}$, implying the $|\mathcal{S}_C^{(1)}|$ should be sufficiently large as to capture this structure accurately.

We now focus attention on defining the quantile envelope over $\mathcal{S}_C^{(1)}$ using a technique paralleling that described in \Cref{section:quantile_envelopes}. In particular, we start by selecting the projection directions $\{u_{m}\}$ of \Cref{eqn:quantile_envelope}; since $s\in\mathbb{R}_{+}^{K}$, we similarly restrict $u_m\in\mathcal{S}_{+}^{K-1} := \mathcal{S}^{K-1}\cap\mathbb{R}_{+}^{K}$.
To best approximate \Cref{eqn:quantile_envelope}, we wish for $\{u_{m}\}$ to be uniformly distributed over $\mathcal{S}_{+}^{K-1}$; however, exactly finding an evenly distributed set of points over hyperspheres in arbitrary $n$-dimensional spaces is a classically difficult problem \cite{schnabel2022simple} 
If $K=2$, we can solve this exactly; for $K > 2$, we generate directions stochastically such that $U\sim\mathrm{Unif}(\mathcal{S}_{+}^{K-1})$ by drawing $V_{1},...,V_{M}\sim\mathcal{N}(0,I^{K\times K})$ and defining $U_{i} := V_{i}^{|\cdot|} / \sqrt{V_{1}^{2} + ... + V_{M}^{2}}$, where $v^{|\cdot|}$ denotes the component-wise absolute values. 

We now wish to define the quantile thresholds $\{\widetilde{q}_{m}\}$ for the selected directions to optimally capture $1-\alpha$ of $\mathcal{S}_C^{(1)}$. 
Naively taking the $1-\alpha$ quantile per projection direction $u_{m}$ results in \textit{joint} coverage by $\widetilde{\mathcal{Q}} := \bigcap_{m=1}^{M} H(u_{m}, \widetilde{q}_{m})$ of $\mathcal{S}^{(1)}_{\mathcal{C}}$ to be $<1-\alpha$. A straightforward fix is to replace the $1-\alpha$ quantile per direction instead with its Bonferroni-corrected $1-\alpha/M$ quantile. While valid, this approach produces overly conservative prediction regions. We, therefore, instead tune a separate $\beta\in(\alpha/M, \alpha)$ parameter via binary search, finding the maximum $\beta^{*}$ such that using the $\beta^{*}$ quantile per direction provides the overall desired coverage, i.e., $|\bigcap_{m=1}^{M} H(u_{m}, \widetilde{q}_{m}(1-\beta^{*}))\cap \mathcal{S}^{(1)}_{\mathcal{C}}| / N_{\mathcal{C}_{1}} \in(1-\alpha,1-\alpha+\epsilon)$ for some fixed, small $\epsilon > 0$. With this choice of $\{(u_{m}, \widetilde{q}_{m})\}$, we have a defined pre-ordering, whose coverage guarantees are formally stated below.

\begin{theorem}\label{thm:CSA_validity}
Suppose $(X_1, Y_1), \dots, (X_{N_C}, Y_{N_C}), (X', Y')$ are exchangeable, where $\mathcal{D}_C := \{(X_i,Y_i)\}_{i=1}^{N_{C}}$. Assume further that $K$ non-negative maps $s_{k} : \mathcal{X}\times\mathcal{Y}\rightarrow\mathbb{R}_ +$ have been defined and a composite $s(X,Y) := (s_1(X,Y),...,s_{K}(X,Y))$ is defined.

Let $\sigma = (\sigma_1, \dots, \sigma_{N_C})$ be a random permutation of the indices $\{1, \dots, N_C\}$, drawn uniformly and independently of $\mathcal{D}_C$ and $(X',Y')$. Let the calibration set $\mathcal{D}_C$ be partitioned into $\mathcal{D}_C^{(1)} := \{(X_{\sigma_j}, Y_{\sigma_j})\}_{j=1}^{N_{C_1}}$ and $\mathcal{D}_C^{(2)} := \{(X_{\sigma_j}, Y_{\sigma_j})\}_{j=N_{C_1}+1}^{N_{C_1} + N_{C_2}}$, where $N_{C} := N_{C_1} + N_{C_2}$. Let the corresponding score sets be $\mathcal{S}_{C}^{(1)}$ and $\mathcal{S}_{C}^{(2)}$. Let $T(\cdot; \mathcal{S}_{C}^{(1)}): \mathbb{R}_{+}^K \to \mathbb{R}$ be a deterministic function for any given realization of $\mathcal{S}_{C}^{(1)}$.

For some $\alpha\in(0,1)$, let $\hat{t}$ be the $\lceil(N_{C_{2}}+1)(1-\alpha)\rceil$-th smallest value of the set of transformed scores $\{T(s_i; \mathcal{S}_{C}^{(1)}) \mid s_i \in \mathcal{S}_{C}^{(2)}\}$. Assume that ties among the transformed scores occur with probability zero.  Then, denoting by $\mathcal{C}(X') = \{ y \in \mathcal{Y} \mid T(s(X', y); \mathcal{S}_{C}^{(1)}) \le \hat{t} \}$,
$ \mathcal{P}(Y' \in \mathcal{C}(X')) \ge 1-\alpha, $
where the probability is defined over the joint draw of the data $\mathcal{D}_C$, $(X',Y')$, and the permutation $\sigma$.
\end{theorem}

\begin{proof}
    The overall probability is taken over the joint distribution of the exchangeable data, $\mathcal{D}_C$ and $(X',Y')$, and the independent random permutation, $\sigma$. We use the law of total probability by first conditioning on a specific realization of the permutation, $\sigma = \pi$, and the data in the first split, $\mathcal{D}_C^{(1)} = d^{(1)}$. Given $\sigma = \pi$ and $\mathcal{D}_C^{(1)} = d^{(1)}$, the score set $\mathcal{S}_{C}^{(1)}$ is fixed. As a result, the function $T(\cdot; \mathcal{S}_{C}^{(1)})$ becomes a fixed, deterministic transformation.

    By the initial exchangeability of all data points, after conditioning on the values of the first split $\mathcal{D}_C^{(1)}$, the remaining $N_{C_2}$ calibration points in $\mathcal{D}_C^{(2)}$ and the test point $(X', Y')$ are still an exchangeable sequence. Applying the fixed transformation $T$ to their scores yields an exchangeable sequence of $N_{C_2} + 1$ scalar values:
    $$ \{T(s_i; \mathcal{S}_{C}^{(1)}) \mid (X_i, Y_i) \in \mathcal{D}_C^{(2)}\} \cup \{T(s(X', Y'); \mathcal{S}_{C}^{(1)})\} $$
    Under the no-ties assumption, the rank of the test value $T(s(X', Y'); \mathcal{S}_{C}^{(1)})$ within this sequence is uniformly distributed on $\{1, \dots, N_{C_2}+1\}$. The test point $Y'$ is covered if its transformed score is less than or equal to the threshold $\hat{t}$. This occurs if and only if the rank of the test score is at most $m = \lceil(N_{C_2}+1)(1-\alpha)\rceil$. The probability of this event, conditional on $\sigma=\pi$ and $\mathcal{D}_C^{(1)} = d^{(1)}$, is:
    $$
    \mathcal{P}(Y' \in \mathcal{C}(X') \mid \sigma = \pi, \mathcal{D}_C^{(1)} = d^{(1)}) = \frac{\lceil(N_{C_2}+1)(1-\alpha)\rceil}{N_{C_2}+1} \ge 1-\alpha.
    $$
    Since this guarantee holds for any realization $(\pi, d^{(1)})$, the unconditional probability also holds by the law of total probability:
    $$
    \mathcal{P}(Y' \in \mathcal{C}(X')) = \mathbb{E}_{\sigma, \mathcal{D}_C^{(1)}}\left[\mathcal{P}(Y' \in \mathcal{C}(X') \mid \sigma, \mathcal{D}_C^{(1)})\right] \ge \mathbb{E}_{\sigma, \mathcal{D}_C^{(1)}}[1-\alpha] = 1-\alpha,
    $$
    where the expectation is taken over the joint distribution of $\sigma$ and $\mathcal{D}_C^{(1)}$. This completes the proof.
\end{proof}

\subsubsection{Score Quantile Threshold}\label{section:quantile_env}
To then compute $\widehat{q}$, we find $t^{*}(s)$ for each $s\in \mathcal{S}^{(2)}_{\mathcal{C}}$, defined to be $\min \{t\in\mathbb{R}: s\in\bigcap_{m=1}^{M} H(u_{m}, t\widetilde{q}_{m})\}$. This can be efficiently computed as $t^{*}(s) = \max_{m=1,...,M} (u_{m}^{\top} s / \widetilde{q}_{m})$. Denoting the $\ceil{(N_{\mathcal{C}_{2}}+1)(1-\alpha)}$-th largest $t^{*}(s)$ as $\widehat{t}$, $\widehat{q}_{m} := \widehat{t}\widetilde{q}_{m}$ and $\widehat{\mathcal{Q}} := \bigcap_{m=1}^{M} H(u_{m}, \widehat{q}_{m})$. If the tightest quantile envelope was already discovered over $\mathcal{S_C}^{(1)}$, this adjustment factor $\widehat{t}\approx 1$. Critically, such calculations can be computed efficiently in vector form. We present the full algorithm in \Cref{alg:CSA}.

Importantly, while this procedure will result in convex regions $\widehat{\mathcal{Q}}$, this does \textbf{not} mean the downstream prediction regions in $\mathcal{Y}$ will be convex. 
However, it is unsurprising such flexibility exists, as even a single \textit{scalar} score $s_1(x,y)$ can produce nonconvex prediction regions. One additional notable property of the CSA prediction regions is that their sizes vary across $x$ even if such variability is not baked into the constituent scores. For instance, using $s_k(x,y) := | f_k(x) - y |$ with standard, scalar conformal prediction yields intervals of length $2\widehat{q}_k$ for \textit{any} $x$, yet $|\mathcal{C}^{\mathrm{CSA}}(x)|$ even with such $\{s_k(x,y)\}$ \textit{will} vary with $x$. This variability is desirable, as predictive uncertainty is seldom uniform across the covariate space.

\begin{algorithm}
  \caption{\label{alg:CSA} CSA: UnifHypersphere(K) is an assumed subroutine that samples $\sim\mathrm{Unif}(\mathcal{S}^{K-1})$.
  }
  \begin{algorithmic}[1]
    \STATE \textbf{Inputs: } Score functions $s_{1},...,s_{K} : \mathcal{X}\rightarrow\mathcal{Y}$, Calibration set $\mathcal{D_C}$, Desired coverage $1-\alpha$ 
    \STATE $[\beta_{\mathrm{lo}},\beta_{\mathrm{hi}}]\gets[\alpha/M, \alpha], \widehat{\mathcal{Q}}\gets\emptyset$
    \STATE $\sigma \sim \mathrm{Unif}(\text{Permutations of } \{1,\ldots,N_C\})$
    \STATE $\mathcal{S_C}^{(1)} \cup \mathcal{S_C}^{(2)} \gets \{(s_{k}(x_{\sigma(i)},  y_{\sigma(i)}))_{k=1}^{K}\}_{i=1,N_{\mathcal{C}_1}+1}^{N_{\mathcal{C}_1},N_{\mathcal{C}_2}}
    ,\quad\{u_{m}\gets\textsc{UnifHypersphere}(K)\}_{m=1}^{M}$
    \WHILE $|\mathcal{S}^{(1)}_{\mathcal{C}} \bigcap \widehat{\mathcal{Q}}| / N_{\mathcal{C}_1} \notin 1-\alpha\pm\epsilon$
    \STATE $\beta\gets (\beta_{\mathrm{lo}}+\beta_{\mathrm{hi}}) / 2 $
    \STATE $\left\{\widetilde{q}_{m}\gets (1-\beta) \text{ empirical quantile of } \{ u_{m}^{\top}s_{i}\}_{s_i\in S_C^{(1)}}\right\}_{m=1}^{M}$
    \STATE $\widehat{\mathcal{Q}}\gets\bigcap_{m=1}^{M} H(u_{m}, \widetilde{q}_{m})$
    \STATE \textbf{if} $|\mathcal{S}^{(1)}_{\mathcal{C}} \bigcap \widehat{\mathcal{Q}}| / N_{\mathcal{C}_1} > 1-\alpha$ \textbf{then} $\beta_{\mathrm{lo}}\gets\beta$
    \textbf{else} $\beta_{\mathrm{hi}}\gets\beta$
    \ENDWHILE
    \STATE $\widehat{t}\gets (1-\alpha) \text{ empirical quantile of } \{\max_{m\in[M]} (u_{m}^{\top} s_{i} / \widetilde{q}_{m})\}_{s_i\in S_C^{(2)}}$
    \STATE \textbf{Return} $\{(u_{m}, \widehat{t}\widetilde{q}_{m})\}_{m=1}^{M}$
    \end{algorithmic}
\end{algorithm}

Notably, this algorithm achieves the aforementioned coverage guarantee as a direct corollary of \Cref{thm:CSA_validity}, stated below. Intuitively, the proof proceeds by demonstrating that the $T$ scoring function defined implicitly by \Cref{alg:CSA} satisfies those conditions posited in \Cref{thm:CSA_validity}, from which the posited coverage immediately follows.

\begin{corollary}\label{col:alg_validity}
Let $\mathcal{D}_C$, $(X', Y')$, $\{s_k\}^{K}_{k=1}$, and $\alpha$ be as defined in \Cref{thm:CSA_validity}. Let $\sigma$, $(\mathcal{S}_C^{(1)}, \mathcal{S}_C^{(2)})$, and $U = \{u_m\}_{m=1}^M$ be as defined by lines 3-4 of the call $CSA(\{s_k\}, \mathcal{D}_C, 1-\alpha)$ of \Cref{alg:CSA}. Denote by $\{\tilde{q}_ m\}_{m=1}^M$ the parameters defined by lines 4-9 of Algorithm 1 and by $T$ the scoring function $T(s; \mathcal{S}_{C}^{(1)}, U) = \max_{m=1,\dots,M} (u_m^\top s / \tilde{q}_ m) $ for any score vector $s \in \mathbb{R}_{+}^K$. Then, denoting by $\mathcal{C}(X') = \{ y \in \mathcal{Y} \mid T(s(X', y); \mathcal{S}_{C}^{(1)}) \le \hat{t} \}$, $ \mathcal{P}(Y' \in \mathcal{C}(X')) \ge 1-\alpha, $ where the probability is defined over the joint draw of the data $\mathcal{D}_C$, $(X',Y')$, and the permutation $\sigma$.
\end{corollary}

\begin{proof}
    To prove the corollary, we must show that this specific function $T$ satisfies the conditions of Theorem 1. The overall probability is taken over the joint draw of the data ($\mathcal{D}_C, (X',Y')$), the random permutation $\sigma$, and the random directions $U$. We use the law of total probability by conditioning on specific realizations of the random elements $\sigma=\pi$, $\mathcal{D}_C^{(1)}=d^{(1)}$, and $U=u$.
    
    Given these fixed realizations, the score set $\mathcal{S}_{C}^{(1)}$ and the projection directions $\{u_m\}$ are fixed. The procedure in Algorithm 1 to find the base quantiles $\{\tilde{q}_ m\}$ via binary search is a deterministic operation on this fixed data. Therefore, the function $T(s; \mathcal{S}_{C}^{(1)}, U)$ becomes a fixed, deterministic function of $s$. The conditions of Theorem 1 are met (again assuming no ties in $T$), and its proof implies that the conditional probability of coverage is at least $1-\alpha$:
    $$
    \mathcal{P}(Y' \in \mathcal{C}(X') \mid \sigma = \pi, \mathcal{D}_C^{(1)} = d^{(1)}, U = u) \ge 1-\alpha.
    $$
    Since this guarantee holds for any realization $(\pi, d^{(1)}, u)$, the unconditional guarantee follows from the law of total probability:
    $$
    \mathcal{P}(Y' \in \mathcal{C}(X')) = \mathbb{E}_{\sigma, \mathcal{D}_C^{(1)}, U}\left[\mathcal{P}(Y' \in \mathcal{C}(X') \mid \sigma, \mathcal{D}_C^{(1)}, U)\right] \ge 1-\alpha.
    $$
    Thus, the guarantee holds for the specific procedure in Algorithm 1.
\end{proof}